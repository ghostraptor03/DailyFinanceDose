2025-05-28 20:57:32 [scrapy.utils.log] INFO: Scrapy 2.13.1 started (bot: financial_news_scraper)
2025-05-28 20:57:32 [scrapy.utils.log] INFO: Versions:
{'lxml': '5.4.0',
 'libxml2': '2.11.9',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '24.11.0',
 'Python': '3.13.3 (tags/v3.13.3:6280bb5, Apr  8 2025, 14:47:33) [MSC v.1943 '
           '64 bit (AMD64)]',
 'pyOpenSSL': '25.1.0 (OpenSSL 3.5.0 8 Apr 2025)',
 'cryptography': '45.0.3',
 'Platform': 'Windows-11-10.0.26100-SP0'}
2025-05-28 20:57:32 [scrapy.addons] INFO: Enabled addons:
[]
2025-05-28 20:57:32 [scrapy.extensions.telnet] INFO: Telnet Password: a1a8708fcae22dba
2025-05-28 20:57:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-05-28 20:57:32 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'AUTOTHROTTLE_MAX_DELAY': 10,
 'AUTOTHROTTLE_START_DELAY': 1,
 'AUTOTHROTTLE_TARGET_CONCURRENCY': 2.0,
 'BOT_NAME': 'financial_news_scraper',
 'CONCURRENT_REQUESTS_PER_DOMAIN': 4,
 'DOWNLOAD_DELAY': 2,
 'LOG_FILE': 'logs/scraper_20250528_205732.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'financial_news_scraper.spiders',
 'RANDOMIZE_DOWNLOAD_DELAY': 0.5,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['financial_news_scraper.spiders'],
 'USER_AGENT': 'financial_news_scraper (+https://github.com/yourusername)'}
2025-05-28 20:57:32 [twisted] CRITICAL: Unhandled error in Deferred:
2025-05-28 20:57:32 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\zacht\FinanceCrawler\DailyFinanceDose\.venv\Lib\site-packages\scrapy\core\engine.py", line 110, in __init__
    self.downloader: Downloader = downloader_cls(crawler)
                                  ~~~~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\zacht\FinanceCrawler\DailyFinanceDose\.venv\Lib\site-packages\scrapy\core\downloader\__init__.py", line 109, in __init__
    DownloaderMiddlewareManager.from_crawler(crawler)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\zacht\FinanceCrawler\DailyFinanceDose\.venv\Lib\site-packages\scrapy\middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zacht\FinanceCrawler\DailyFinanceDose\.venv\Lib\site-packages\scrapy\middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
  File "C:\Users\zacht\FinanceCrawler\DailyFinanceDose\.venv\Lib\site-packages\scrapy\utils\misc.py", line 71, in load_object
    mod = import_module(module)
  File "C:\Users\zacht\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py", line 88, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'scrapy_playwright.middleware'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\zacht\FinanceCrawler\DailyFinanceDose\.venv\Lib\site-packages\twisted\internet\defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\zacht\FinanceCrawler\DailyFinanceDose\.venv\Lib\site-packages\scrapy\crawler.py", line 156, in crawl
    self.engine = self._create_engine()
                  ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\zacht\FinanceCrawler\DailyFinanceDose\.venv\Lib\site-packages\scrapy\crawler.py", line 169, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\zacht\FinanceCrawler\DailyFinanceDose\.venv\Lib\site-packages\scrapy\core\engine.py", line 113, in __init__
    self.close()
    ~~~~~~~~~~^^
  File "C:\Users\zacht\FinanceCrawler\DailyFinanceDose\.venv\Lib\site-packages\scrapy\core\engine.py", line 173, in close
    self.downloader.close()
    ^^^^^^^^^^^^^^^
AttributeError: 'ExecutionEngine' object has no attribute 'downloader'. Did you mean: '_downloaded'?
